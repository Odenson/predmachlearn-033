
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #!/usr/bin/R --verbose
>
> require(dplyr, quietly = TRUE)
> require(caret, quietly = TRUE)
> # require(lubridate, quietly = TRUE)
> # require(ggplot2, quietly = TRUE)
>
> starttime <- proc.time()
>
> # load raw data
> raw <- read.csv("data/pml-training.csv", header = TRUE,
+                 na.strings = c("NA", "#DIV/0!"), stringsAsFactors = FALSE)
>
> # set factors classe (for outcome), num_window for partitioning
> # raw$cvtd_timestamp <- dmy_hm(raw$cvtd_timestamp)
> # raw$num_window <- factor(raw$num_window)
> raw$classe <- factor(raw$classe)
>
> # order by window num and raw_timestamp_part_2 to mimic a timeseries
> raw <- arrange(raw, num_window, raw_timestamp_part_2)
>
> # qplot(num_window, cvtd_timestamp, data = raw[raw$user_name == "carlitos",], colour = classe)
> #qplot(num_window, classe, data = raw[raw$user_name == "carlitos",], colour = classe)
> #qplot(num_window, classe, data = raw, colour = classe)
>
> # split into train (70%) and test (30%) on classe
> set.seed(033)
> rawindex <- createDataPartition(raw$classe, p = 0.7, list = FALSE, times = 1)
> training <- raw[rawindex,]
> testing <- raw[-rawindex,]
>
> # do we have a good classe split?
> # levels(training$classe)
> # levels(testing$classe)
>
> # do we have any window overlap between train and test?
> # intersect(unique(training$num_window), unique(testing$num_window))
>
> # ignore columns that are more than 95% empty (i.e. NA):
> nas.perc <- as.integer(0.95 * nrow(raw))
> nas <- sort(apply(raw, 2, function(x) length(which(is.na(x)))), decreasing = TRUE)
> bad.names <- names(nas[nas >= 19216])
> # print(bad.names)
> good.names <- setdiff(names(training), bad.names)
> # print(good.names)
>
> # exclude columns that do not aid in prediction (or are an outcome)
> train.names <- sort(
+     grep(paste("classe", "_window", "user_name", "X", "_timestamp", sep = "|"),
+          good.names, value = TRUE, invert = TRUE))
> # print(train.names)
>
> # use these column names to generate training formula
> train.formula <- as.formula(paste("classe ~ ", paste(train.names, collapse = "+")))
> print(train.formula)
classe ~ accel_arm_x + accel_arm_y + accel_arm_z + accel_belt_x +
    accel_belt_y + accel_belt_z + accel_dumbbell_x + accel_dumbbell_y +
    accel_dumbbell_z + accel_forearm_x + accel_forearm_y + accel_forearm_z +
    gyros_arm_x + gyros_arm_y + gyros_arm_z + gyros_belt_x +
    gyros_belt_y + gyros_belt_z + gyros_dumbbell_x + gyros_dumbbell_y +
    gyros_dumbbell_z + gyros_forearm_x + gyros_forearm_y + gyros_forearm_z +
    magnet_arm_x + magnet_arm_y + magnet_arm_z + magnet_belt_x +
    magnet_belt_y + magnet_belt_z + magnet_dumbbell_x + magnet_dumbbell_y +
    magnet_dumbbell_z + magnet_forearm_x + magnet_forearm_y +
    magnet_forearm_z + pitch_arm + pitch_belt + pitch_dumbbell +
    pitch_forearm + roll_arm + roll_belt + roll_dumbbell + roll_forearm +
    total_accel_arm + total_accel_belt + total_accel_dumbbell +
    total_accel_forearm + yaw_arm + yaw_belt + yaw_dumbbell +
    yaw_forearm
>
> # model using random forest
> model <- train(train.formula, data = training, method = "rf")
>
> # save model
> saveRDS(model, "data/model.rds")
>
> elapsedtime <- proc.time() - starttime
>
> print("Total elapsed time is:")
[1] "Total elapsed time is:"
> print(elapsedtime)
    user   system  elapsed
3909.432   14.272 3920.882
>

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1669    7    0    0    0
         B    5 1127   10    0    0
         C    0    5 1016   23    0
         D    0    0    0  937    1
         E    0    0    0    4 1081

Overall Statistics

               Accuracy : 0.9907
                 95% CI : (0.9879, 0.993)
    No Information Rate : 0.2845
    P-Value [Acc > NIR] : < 2.2e-16

                  Kappa : 0.9882
 Mcnemar's Test P-Value : NA

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9970   0.9895   0.9903   0.9720   0.9991
Specificity            0.9983   0.9968   0.9942   0.9998   0.9992
Pos Pred Value         0.9958   0.9869   0.9732   0.9989   0.9963
Neg Pred Value         0.9988   0.9975   0.9979   0.9945   0.9998
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2836   0.1915   0.1726   0.1592   0.1837
Detection Prevalence   0.2848   0.1941   0.1774   0.1594   0.1844
Balanced Accuracy      0.9977   0.9932   0.9922   0.9859   0.9991


> varImp(model)
rf variable importance

  only 20 most important variables shown (out of 52)

                     Overall
roll_belt             100.00
yaw_belt               84.12
magnet_dumbbell_z      72.32
pitch_forearm          69.63
magnet_dumbbell_y      65.94
pitch_belt             61.21
magnet_dumbbell_x      54.01
roll_forearm           53.60
accel_belt_z           46.04
magnet_belt_z          44.64
accel_dumbbell_y       44.62
magnet_belt_y          44.04
roll_dumbbell          43.97
roll_arm               39.06
accel_dumbbell_z       38.74
accel_forearm_x        34.34
gyros_belt_z           33.61
total_accel_dumbbell   31.02
accel_dumbbell_x       30.74
gyros_dumbbell_y       30.01
