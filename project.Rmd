---
title: "Predict Correct Use of Dumbbells"
author: "Frank Jung"
date: "21 October 2015"
output:
  html_document:
    fig_caption: yes
    highlight: monochrome
    toc: yes
---

```{r initialisation, echo=FALSE, message=FALSE, warning=FALSE}
require(knitr, quietly = TRUE)
require(caret, quietly = TRUE)
require(dplyr, quietly = TRUE)
require(ggplot2, quietly = TRUE)
require(rfUtilities, quietly = TRUE)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r load, echo=FALSE}
# load raw data
raw <- read.csv("data/pml-training.csv", header = TRUE,
                na.strings = c("NA", "#DIV/0!"), stringsAsFactors = FALSE)

# set classe as a factor
raw$classe <- factor(raw$classe)
```

## Overview

This report describes the algorithm used to predict how well people perform the
exercise of lifting a dumbbell. This is a classification problem where
predictors are used to determine one of five [outcomes](#goal). This report
will:

* [describe the choices made in choosing a model](#choice-of-prediction-algorithm)
* [describe how the model was built](#data-partitioning)
* [cross validate the model](#testing)
* [estimate the out-of-sample error rate](#estimation-of-error-rate)

Links to data and further information of the original research can be found in
the [appendices](#references).

### Background

Using devices such as [Jawbone Up](https://jawbone.com/up), [Nike
FuelBand](http://www.nike.com/), and [Fitbit](https://www.fitbit.com) it is now
possible to collect a large amount of data about personal activity relatively
inexpensively. These type of devices are part of the quantified self movement,
a group of enthusiasts who take measurements about themselves regularly to
improve their health, to find patterns in their behavior, or because they are
tech geeks. One thing that people regularly do is quantify how much of a
particular activity they do, but they rarely quantify how well they do it.

### Goal

Here we wish to predict the manner in which people do an exercise from data
collected from accelerometers on the belt, forearm, arm, and dumbbell of 6
participants. They were asked to perform dumbbell lifts correctly and
incorrectly in 5 different ways:

```{r classe-table}
classeId <- c(levels(raw$classe))
classeDesc <- c("exactly according to the specification",
                 "throwing the elbows to the front",
                 "lifting the dumbbell only halfway",
                 "lowering the dumbbell only halfway",
                 "and throwing the hips to the front")
classeTable <- data.frame(Classe = classeId, Description = classeDesc)
kable(classeTable, caption = "Classes of exercise activity")
```

The prediction algorithm will determine which classification an exercise falls
into.

## Exploratory Analysis

The ``classe`` field is a categorical outcome, which we will treat as a factor.

The data contains a large number (`r ncol(raw)`) of columns. However, many of
these columns contain little or no information or contain an Excel ``#DIV/0!``
conversion error. Consequently, we will exclude from the prediction formula
all columns with a 95% or higher of missing data.

A number of columns will also be excluded since they do not provide value to
prediction. They are:

| Column | Reason |
|--------|--------|
| ``X`` | Row index not related to a measurement |
| ``*_window``, ``*_timestamp*`` | measurements were made in time segments with overlap so they can be treated as discrete and not time dependent |
| ``user_name`` | who performed the action is not relevant as all were supervised to ensure consistent actions |

Table: Additional columns to ignore

## Training

### Choice of Prediction Algorithm

A good performing prediction algorithm for classification problems is [Random
Forest](https://en.wikipedia.org/wiki/Random_forest). It is resilient to
outliers but is affected by multi-collinearity. This will be
tested [later](#check-multi-collinearity).

### Data Partitioning

The [training data](#data) was partitioned into two:

* training (70%) - used to train model
* testing (30%) - used for [cross-validation](#testing), and estimation of the [error rate](#estimation-of-error-rate)

```{r partition, echo = TRUE}
# split into train (70%) and test (30%) on outcome (classe)
set.seed(033)
rawindex <- createDataPartition(raw$classe, p = 0.7, list = FALSE)
training <- raw[rawindex,]
testing <- raw[-rawindex,]
```

### Training Formula

The model prediction formula is composed of all fields, **except**:

* columns that are more than 95% empty
* non-predictive columns identified in [Table: Additional columns to ignore](#exploratory-analysis)

Applying these conditions gives the prediction formula:

```{r formula, echo = TRUE}
# ignore columns that are more than 95% empty (i.e. NA):
nasPerc <- as.integer(0.95 * nrow(training))
nas <- sort(apply(training, 2, function(x) length(which(is.na(x)))), decreasing = TRUE)
badNames <- sort(names(nas[nas >= nasPerc]))
goodNames <- setdiff(names(training), badNames)

# exclude columns that do not aid in prediction (or are an outcome)
trainNames <-
    grep(
      paste("classe", "window", "user_name", "X", "_timestamp", sep = "|"),
      goodNames, value = TRUE, invert = TRUE
    )

# use these column names to generate training formula
trainFormula <- as.formula(paste("classe ~ ", paste(trainNames, collapse = "+")))
print(trainFormula)
```

This will appear below in training as the variable ``trainFormula``.

### Check Multi-Collinearity

No collinear variables were identified. The predictors used in the formula, were
tested using [rfUtilities](http://cran.r-project.org/package=rfUtilities):

```{r collinear, echo = TRUE}
multi.collinear(dplyr::select(training, one_of(trainNames)))
```

### Training Model

For training we will use a cross-validated Random Forest using the
[caret](http://topepo.github.io/caret/index.html) package. The cross-validation
used here is a simple
[k-fold](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation).
Where k is set to 5.

```r
model <- train(trainFormula, data = training, method = "rf",
               trControl = trainControl(method = "cv", number = 5))
```

```{r train}
# restore saved cross-validated random forest model
if (file.exists("data/model-rf-cv.rds")) {
    model <- readRDS("data/model-rf-cv.rds")
}
# show model
model
```
Where ``mtry`` is the number of randomly selected predictors.

This final model has an accuracy of
**`r round(rfStats(model$finalModel)[1], 3)`**
and an [out-of-bag
(OOB)](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr)
estimate of error rate,
**`r round(100 * (1 - rfStats(model$finalModel)[1]), 3)`%**.

### Variable Importance

A plot of [variable
importance](https://en.wikipedia.org/wiki/Random_forest#Variable_importance)
scaled from 0 (low importance) to 100 (high importance):

```{r varImpPlot}
vi <- varImp(model)

# put into data frame for use in plot and table
viDf <- data.frame(Index = 1:nrow(vi$importance),
                   Variable = as.character(rownames(vi$importance)),
                   Importance = round(vi$importance$Overall, 2))

# plot
ggplot(data = viDf, aes(x = Index, y = Importance)) +
    geom_point(shape = 1) +
    geom_line(colour = "purple") +
    theme_light(base_family = "sans", base_size = 11) +
    scale_y_continuous(breaks = seq(0, 900, by = 50)) +
    scale_x_discrete(breaks = seq(0, 52, by = 2)) +
    labs(y = "Importance (Scaled from 0 to 100)") +
    ggtitle("Variable Importance")
```

The full list by scaled variable importance:

```{r importanceTable}
# full table in decreasing order of importance
kable(arrange(viDf, desc(Importance)), caption = "Variable Importance")
```

## Testing

The model was next cross-validated against the reserved test data:

```{r predict, echo = TRUE}
# cross-validate
testPredict <- predict(model, newdata = testing)
```

### Estimation of Error Rate

Since this is categorical data, estimate using an accuracy measure:

```{r estimateErrorRate, echo = TRUE}
# estimate error (since this is categorical data we are estimating accuracy)
# page 37 (james2013introduction)
estimated <- sum(testPredict != testing$classe) / length(testing$classe)
```

So, against the independent testing dataset, the estimated error rate for this
model is **`r round(100 * estimated, 3)`%**. Note that this is a more
pessimistic estimate than the [OOB estimated of error rate](#training-model).

## Predictions

The model was then used to predict ``classe`` outcomes for a validation data
set:

```{r validation, echo = TRUE}
validation <- read.csv("data/pml-testing.csv", header = TRUE,
                       na.strings = c("NA", "#DIV/0!"), stringsAsFactors = FALSE)

predictions <- predict(model, newdata = validation)
results <- data.frame(Classe = as.character(predictions))
rownames(results) <- 1:length(predictions)
kable(t(results), align = "c", caption = "Model Predictions for Validation Data")
```

## Appendices

### References

* Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. [Qualitative Activity Recognition of Weight Lifting Exercises](http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201). Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. ([PDF](http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf))

* Book (hastie2009elements) Hastie, T.; Tibshirani, R. & Friedman, J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition Springer, 2009

* Book (james2013introduction) James, G.; Witten, D.; Hastie, T. & Tibshirani, R. An Introduction to Statistical Learning: with Applications in R Springer New York, 2013

### Data

Data for this project was sourced from:

* Training data, https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
* Validation data, https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

### Source

The source code and model data for this report are available from GitHub,
https://github.com/frankhjungdss/predmachlearn-033.

| Name | Description |
|------|-------------|
| getdata.R | download raw CSV data from remote sources |
| model-rf-cv.R | full script to train and test cross-validate random forest model |
| pred-rf-cv.R | prepare predictions for submission |

### Session Information

This report was produced using the following [RStudio](https://www.rstudio.com/)
environment:

```{r session}
sessionInfo()
```
